{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347fa784",
   "metadata": {},
   "source": [
    "# Revisiting Derivatives\n",
    "\n",
    "\n",
    "Your review for derivatives is that the exact derivative is as follows,:\n",
    "\n",
    "$\\frac{df}{dx}=\\lim_{\\Delta x\\rightarrow0}\\frac{f(x+\\Delta x)-f(x)}{\\Delta x}$\n",
    "\n",
    "where $f=f(x)$. In your lessons on initial value problems, you approximated this derivative by removing the $\\lim_{\\Delta t \\rightarrow 0}.$ When you describe derivatives over space, you use the same approximation, but in this notebook you will try a few other alternatives. The following approximation is called a forward difference derivative, \n",
    "\n",
    "$\\frac{\\Delta f}{\\Delta x}\\approx\\frac{f(x+\\Delta x)-f(x)}{\\Delta x},$\n",
    "\n",
    "because you approximate $\\frac{df}{dx}$ using the current $f(x)$ and the forward step, $f(x+\\Delta x)$ as the derivative.\n",
    "\n",
    "\n",
    "## Taylor Series Expansion\n",
    "\n",
    "\n",
    "The approximation of the __truncation error__ in the function near $x_{i}$ is given as:\n",
    "\n",
    "$f(x_{i+1})=f(x_{i})+f'(x_{i})h+\\frac{f''(x_{i})}{2!}h^2+...$\n",
    "\n",
    "where $f'=\\frac{df}{dx}$ and $x_{i+1} = x_{i}+h.$\n",
    "\n",
    "\n",
    "You determine the first order derivative by solving for $f'(x_{i})$:\n",
    "\n",
    "$f'(x_{i})=\\frac{f(x_{i+1})-f(x_{i})}{h}-\\frac{f''(x_{i})}{2!}h+...$\n",
    "\n",
    "The __truncation error__ error is on the order of the timestep, $h$. This is commonly represented in big-O notation as  $error\\approx O(h)$\n",
    "\n",
    "$f'(x_{i})=\\frac{f(x_{i+1})-f(x_{i})}{h}+O(h)$\n",
    "\n",
    "\n",
    "### Higher order derivatives\n",
    "\n",
    "You have already solved first-order numerical derivatives problems in [Project_01](https://github.uconn.edu/rcc02007/CompMech01-Getting-started/blob/master/project/01_Getting-started-project.ipynb) and [CompMech03-IVPs](https://github.uconn.edu/rcc02007/CompMech03-IVPs). Now, you will look at higher order derivatives. Let's start with $\\frac{d^2f}{dx^2}=f''(x)$. We need more information. \n",
    "\n",
    "First, take the function near $x_{i}$ within 1 step, $h$, given as:\n",
    "\n",
    "$f(x_{i+1})=f(x_{i})+f'(x_{i})h+\\frac{f''(x_{i})}{2!}h^2+...$\n",
    "\n",
    "Next, take the function near $x_{i}$ within 2 steps, $2h$, given as: \n",
    "\n",
    "$f(x_{i+2})=f(x_{i})+f'(x_{i})2h+\\frac{f''(x_{i})}{2!}4h^2+...$\n",
    "\n",
    "solving for $f''(x_{i})$ by subtracting $f(x_{i+2})-2f(x_{i+1})$ to eliminate $f'(x_{i})$:\n",
    "\n",
    "$f''(x_{i})=\\frac{f(x_{i+2})-2f(x_{i+1})-3f(x_{i})}{h^2}+O(h)$\n",
    "\n",
    "Here you have the numerical second derivative of a function, $f(x)$, with __truncation error__ of $\\approx O(h)$\n",
    "\n",
    "## Using your numerical derivatives\n",
    "\n",
    "Consider the example of taking the derivative of $f(x) = \\sin(x)$ with only 10 data points per period. Let's assume there is no random error in the signal. First, you can plot the values you expect since you know the derivatives of $\\sin(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.rcParams['lines.linewidth'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a646b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(0,2*np.pi,11)\n",
    "xx=np.linspace(0,2*np.pi,100)\n",
    "## analytical derivatives\n",
    "y=np.sin(x)\n",
    "dy=np.cos(xx)\n",
    "ddy=-np.sin(xx)\n",
    "plt.plot(xx,np.sin(xx),label='f(x)=sin(x)')\n",
    "plt.plot(xx,dy,label='f\\'(x)=cos(x)')\n",
    "plt.plot(xx,ddy,label='f\\'\\'(x)=-sin(x)')\n",
    "plt.plot(x,y,'o',label='measurements')\n",
    "plt.legend(bbox_to_anchor=(1,0.5),loc='center left')\n",
    "plt.title('Plot of sin(x) and its first/second derivatives')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x), f\\'(x), f\\'\\'(x)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb077221",
   "metadata": {},
   "source": [
    "Next, you use your definitions for first and second derivatives to get the approximate derivatives, $f'(x)~and~f''(x)$. You are using a forward difference method so for $f'(x)$ you truncate the values by 1 and for $f''(x)$, you truncate the values by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e9161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## numerical derivatives\n",
    "dy_n=(y[1:]-y[0:-1])/(x[1:]-x[0:-1]);\n",
    "ddy_n=(y[2:]-2*y[1:-1]+y[0:-2])/(x[2:]-x[1:-1])**2;\n",
    "\n",
    "plt.plot(xx,dy,label='analytical dy/dx')\n",
    "plt.plot(x[:-1],dy_n,'o',label='num dy/dx')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e0a23",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "What is the maximum error between the numerical $\\frac{df}{dx}$ and the actual $\\frac{df}{dx}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ddc6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2887203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xx,ddy,label='analytical d2y/dx2')\n",
    "plt.plot(x[:-2],ddy_n,'o',label='num d2y/dx2')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41e402",
   "metadata": {},
   "source": [
    "Your stepsize is $h=\\pi/5\\approx 0.6$. Looking at the graphs, it looks like you are shifting your function to the left by using this forward difference method. That is because you are using a forward difference method, the derivative is going to be averaged between step $i$ and $i+1$. The result is that you shift the function by $h/2$ for each derivative. \n",
    "\n",
    "## Exercise\n",
    "\n",
    "Another first-order, $error\\approx O(h)$, derivative is the backward difference derivative, where\n",
    "\n",
    "$f'(x_{i})=\\frac{f(x_{i})-f(x_{i-1})}{h}+O(h)$\n",
    "\n",
    "$f''(x_{i})=\\frac{f(x_{i})-2f(x_{i-1})+f(x_{i-2})}{h^2}+O(h)$\n",
    "\n",
    "Plot the first and second derivatives of $\\sin(x)$ using the same x-locations as you did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e35c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46b81bf5",
   "metadata": {},
   "source": [
    "## Central Difference\n",
    "### Increase accuracy with more points\n",
    "\n",
    "Both the forward and backward difference methods have the same $error\\approx O(h)$, _but you can do better._ Let's rewrite Taylor series of the function, $f(x)$,  near $x_{i}$ is given as:\n",
    "\n",
    "forward:\n",
    "\n",
    "$f(x_{i+1})=f(x_{i})+f'(x_{i})h+\\frac{f''(x_{i})}{2!}h^2-\\frac{f'''(x_{i})}{3!}h^3+...$\n",
    "\n",
    "backward:\n",
    "\n",
    "$f(x_{i-1})=f(x_{i})-f'(x_{i})h+\\frac{f''(x_{i})}{2!}h^2-\\frac{f'''(x_{i})}{3!}h^3+...$\n",
    "\n",
    "Now, you subtract $f(x_{i+1})-f(x_{i-1})$, then solve for $f'(x_{i})$, as such\n",
    "\n",
    "$f'(x_{i})=\\frac{f(x_{i+1})-f(x_{i-1})}{2h}+O(h^{2}).$\n",
    "\n",
    "The result is that the __truncation error__ has been reduced to $\\approx O(h^2).$ Take a look at the new function. The derivative is based upon the two closest points, $x_{i-1}~and~x_{i+1}$, but not $x_{i}$. \n",
    "\n",
    "This approximation is called the __central difference method__. You can also apply it to second derivatives as such\n",
    "\n",
    "forward: \n",
    "\n",
    "$f(x_{i+1})=f(x_{i})+f'(x_{i})h+\\frac{f''(x_{i})}{2!}h^2-\\frac{f'''(x_{i})}{3!}h^3+...$\n",
    "\n",
    "backward:\n",
    "\n",
    "$f(x_{i-1})=f(x_{i})-f'(x_{i})h+\\frac{f''(x_{i})}{2!}h^2-\\frac{f'''(x_{i})}{3!}h^3+...$\n",
    "\n",
    "\n",
    "Finally, you add $f(x_{i+1})+f(x_{i-1})$ to eliminate $f'(x_i)$ and solve for $f''(x_i)$ as such\n",
    "\n",
    "$f''(x_{i}) = \\frac{f(x_{i+1})-2f(x_{i})+f(x_{i-1})}{h^2} + O(h^2).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(0,2*np.pi,11);\n",
    "## analytical derivatives\n",
    "y=np.sin(x);\n",
    "dy=np.cos(xx);\n",
    "ddy=-np.sin(xx);\n",
    "\n",
    "## forward difference\n",
    "dy_f=(y[1:]-y[:-1])/(x[1:]-x[:-1]);\n",
    "## central difference\n",
    "dy_c=(y[2:]-y[:-2])/(x[2:]-x[:-2]);\n",
    "\n",
    "plt.plot(xx,dy,label='analytical dy/dx')\n",
    "plt.plot(x[:-1],dy_f,'o',label='fwd difference')\n",
    "plt.plot(x[1:-1],dy_c,'s',label='central difference')\n",
    "plt.legend(bbox_to_anchor=(1,0.5),loc='center left');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad037a2",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Plot the analytical, forward difference, and central difference results for the second derivative of $\\sin(x)$. \n",
    "\n",
    "## Higher order derivatives\n",
    "\n",
    "You use the following chart for commonly found derivatives and the corresponding Forward, Backward, and Central difference approximations. In practice, you should use __central difference__ approximations because they reduce the truncation error from $O(h)\\rightarrow O(h^2)$ without using more data points to calculate the derivative. \n",
    "\n",
    "__Table of derivatives and the corresponding forward, backward, and central difference method equations.__\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"\" xml:lang=\"\">\n",
    "<head>\n",
    "  <meta charset=\"utf-8\" />\n",
    "  <meta name=\"generator\" content=\"pandoc\" />\n",
    "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" />\n",
    "  \n",
    "  <style>\n",
    "    code{white-space: pre-wrap;}\n",
    "    span.smallcaps{font-variant: small-caps;}\n",
    "    span.underline{text-decoration: underline;}\n",
    "    div.column{display: inline-block; vertical-align: top; width: 50%;}\n",
    "    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}\n",
    "    ul.task-list{list-style: none;}\n",
    "  </style>\n",
    "  <script src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\" type=\"text/javascript\"></script>\n",
    "  <!--[if lt IE 9]>\n",
    "    <script src=\"//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js\"></script>\n",
    "  <![endif]-->\n",
    "</head>\n",
    "<body>\n",
    "<table>\n",
    "<colgroup>\n",
    "<col style=\"width: 17%\" />\n",
    "<col style=\"width: 24%\" />\n",
    "<col style=\"width: 24%\" />\n",
    "<col style=\"width: 33%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th>Derivative</th>\n",
    "<th>Forward <span class=\"math inline\">\\(O(h)\\)</span></th>\n",
    "<th>Backward <span class=\"math inline\">\\(O(h)\\)</span></th>\n",
    "<th>Central <span class=\"math inline\">\\(O(h^2)\\)</span></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"odd\">\n",
    "<td><span class=\"math inline\">\\(\\frac{df}{dx}\\)</span></td>\n",
    "<td><span class=\"math inline\">\\(\\frac{f(x_{i+1})-f(x_i)}{h}\\)</span></td>\n",
    "<td><span class=\"math inline\">\\(\\frac{f(x_{i})-f(x_{i-1})}{h}\\)</span></td>\n",
    "<td><span class=\"math inline\">\\(\\frac{f(x_{i+1})-f(x_{i-1})}{2h}\\)</span></td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td><span class=\"math inline\">\\(\\frac{d^2f}{dx^2}\\)</span></td>\n",
    "<td><span class=\"math inline\">\\(\\frac{f(x_{i+2})-2f(x_{i+1})-3f(x_{i})}{h^2}\\)</span></td>\n",
    "<td><span class=\"math inline\">\\(\\frac{f(x_{i})-2f(x_{i-1})+f(x_{i-2})}{h^2}\\)</span></td>\n",
    "<td><span class=\"math inline\">\\(\\frac{f(x_{i+1})-2f(x_{i})+f(x_{i-1})}{h^2}\\)</span></td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td><span class=\"math inline\">\\(\\frac{d^3f}{dx^3}\\)</span></td>\n",
    "<td><span class=\"math inline\">\\(\\frac{f (x_{i+3} ) − 3 f (x_{i+2} ) + 3 f (x_{i+1} ) − f(x_{ i} )}{h^3}\\)</span></td>\n",
    "<td><span class=\"math inline\">\\(\\frac{f (x_i ) − 3 f (x_{i−1} ) + 3 f (x_{i−2} ) − f (x_{i−3})}{h^3}\\)</span></td>\n",
    "<td><span class=\"math inline\">\\(\\frac{f (x_{i+2} ) − 2 f (x_{ i+1} ) + 2 f (x_{i−1} ) − f (x_{i−2} )}{2h^3}\\)</span></td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td><span class=\"math inline\">\\(\\frac{d^4f}{dx^4}\\)</span></td>\n",
    "<td><span class=\"math inline\">\\(\\frac{f (x_{i+4} ) − 4 f (x_{i+3} ) + 6 f (x_{i+2} ) − 4 f (x_{i+1} ) + f (x_{i} )}{h^4}\\)</span></td>\n",
    "<td><span class=\"math inline\">\\(\\frac{f (x_i ) − 4 f (x_{i−1} ) + 6 f (x_{i−2} ) − 4 f (x_{i−3} ) + f (x_{i−4} )}{h^4}\\)</span></td>\n",
    "<td><span class=\"math inline\">\\(\\frac{f (x_{i+2} ) − 4 f (x_{i+1} ) + 6 f (x_{i} ) − 4 f (x_{i−1} ) + f (x_{i−2} )}{h^4}\\)</span></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "## What You've Learned\n",
    "\n",
    "* How to approximate error in approximate derivatives\n",
    "* How to approximate derivatives using forward difference methods\n",
    "* How to approximate derivatives using backward difference methods\n",
    "* How to approximate derivatives using central difference methods\n",
    "* How to approximate higher order derivatives with forward, backward, and central differences"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "notebooks//ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
